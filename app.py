import os
import streamlit as st
from langchain.document_loaders import (
    PyPDFLoader, TextLoader, CSVLoader, UnstructuredWordDocumentLoader
)
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain_groq import ChatGroq

# === CONFIG ===
GROQ_API_KEY = "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"  # üîë ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô API Key ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì
MODEL_NAME = "llama3-70b-8192"  # ‡∏´‡∏£‡∏∑‡∏≠ "llama3-8b-8192" ‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö Groq

"""
MODEL_NAME = "mixtral-8x7b-32768"   # ‚úÖ ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ
MODEL_NAME = "llama3-8b-8192"       # ‚úÖ ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ
MODEL_NAME = "llama3-70b-8192"      # ‚úÖ ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ
MODEL_NAME = "gemma-7b-it"          # ‚úÖ ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ
"""

# === Load documents ===
def load_documents():
    all_docs = []
    folder_path = "docs"

    for filename in os.listdir(folder_path):
        file_path = os.path.join(folder_path, filename)

        if filename.endswith(".pdf"):
            loader = PyPDFLoader(file_path)
        elif filename.endswith(".docx"):
            loader = UnstructuredWordDocumentLoader(file_path)
        elif filename.endswith(".txt"):
            loader = TextLoader(file_path)
        elif filename.endswith(".csv"):
            loader = CSVLoader(file_path)
        else:
            continue

        all_docs.extend(loader.load())

    return all_docs

# === Split documents into chunks ===
def split_documents(docs):
    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    return splitter.split_documents(docs)

# === Build FAISS vectorstore ===
def build_vectorstore(chunks):
    embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
    vectordb = FAISS.from_documents(chunks, embedding=embeddings)
    return vectordb

# === Create RAG chain with Groq ===
def create_qa_chain(vectordb):
    llm = ChatGroq(
        temperature=0,
        groq_api_key=GROQ_API_KEY,
        model_name=MODEL_NAME
    )
    chain = RetrievalQA.from_chain_type(llm=llm, retriever=vectordb.as_retriever())
    return chain

# === Streamlit UI ===
def main():
    st.set_page_config(page_title="RAG Chatbot", layout="wide")
    st.title("üí¨ RAG Chatbot ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏á‡∏Ñ‡πå‡∏Å‡∏£")

    with st.spinner("üìö ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•..."):
        docs = load_documents()
        chunks = split_documents(docs)
        vectordb = build_vectorstore(chunks)
        qa_chain = create_qa_chain(vectordb)

    query = st.text_input("üì• ‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì:", placeholder="‡πÄ‡∏ä‡πà‡∏ô ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô‡πÄ‡∏£‡∏≤‡∏°‡∏µ‡∏Å‡∏µ‡πà‡∏ù‡πà‡∏≤‡∏¢?")
    if query:
        with st.spinner("üß† ‡∏Ñ‡∏¥‡∏î‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö..."):
            answer = qa_chain.run(query)
            st.markdown(f"**‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö:** {answer}")

if __name__ == "__main__":
    main()

